# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at https://mozilla.org/MPL/2.0/.

${moduleId}.core.enabled=true
${moduleId}.core.name=repositoryGrid
${moduleId}.core.login=repository
${moduleId}.core.password=repositoryGrid-dev
${moduleId}.core.local.id=
${moduleId}.core.local.host=
${moduleId}.core.public.host=
${moduleId}.core.public.time.port=
${moduleId}.core.local.time.port=47120
${moduleId}.core.local.time.portRange=0
${moduleId}.core.initialMembers=

${moduleId}.core.public.disco.port=
${moduleId}.core.local.disco.port=47110
${moduleId}.core.local.disco.portRange=0
# Ignite default is 0
${moduleId}.core.local.disco.joinTimeout=0
# Ignite default is 5000
${moduleId}.core.local.disco.ackTimeout=5000
# Ignite default is 5000
${moduleId}.core.local.disco.socketTimeout=5000
# Ignite default is 5000, we grant more time to complete operations (e.g. join)
${moduleId}.core.local.disco.networkTimeout=15000

${moduleId}.core.local.disco.registrationRefresh.cron=0 0 2 * * ?

${moduleId}.core.public.comm.port=
${moduleId}.core.local.comm.port=47100
${moduleId}.core.local.comm.portRange=0
# Ignite default is 0, set to 10000 to avoid OOME (and avoid one of the startup WARN messages)
${moduleId}.core.local.comm.messageQueueLimit=10000
# defaults are 5000 and 600000 (quite significant)
# this can cause long join/startup/rebalance scenarios, especially in NATed / Dockerised / Kubernetes environments with unreachable, internal addresses
${moduleId}.core.local.comm.connectTimeout=1000
${moduleId}.core.local.comm.maxConnectTimeout=10000
# Ignite default is 2000
${moduleId}.core.local.comm.socketWriteTimeout=2000
# Ignite default is 1
${moduleId}.core.local.comm.connectionsPerNode=1
# Ignite default is false, might need to be changed in NATed / Dockerised / Kubernetes environment to avoid connection attempts to unreachable, internal addresses
${moduleId}.core.local.comm.filterReachableAddresses=false

${moduleId}.core.failureDetectionTimeout=10000
${moduleId}.core.systemWorkerBlockedTimeout=\${${moduleId}.core.failureDetectionTimeout}

# default is actually Math.max(8, #available_proc_count)
${moduleId}.core.publicThreadPoolSize=8
# default is actually Math.max(8, #available_proc_count)
${moduleId}.core.stripedThreadPoolSize=\${${moduleId}.core.publicThreadPoolSize}
# Ignite default is same as public thread pool size
${moduleId}.core.serviceThreadPoolSize=\${${moduleId}.core.publicThreadPoolSize}
# Ignite default is same as public thread pool size
${moduleId}.core.systemThreadPoolSize=\${${moduleId}.core.publicThreadPoolSize}
# Ignite default is same as public thread pool size
${moduleId}.core.asyncCallbackThreadPoolSize=\${${moduleId}.core.publicThreadPoolSize}
# Ignite default is 4
${moduleId}.core.managementThreadPoolSize=4
# despite p2p being disabled we have to allow pool of 1 thread (default 2)
${moduleId}.core.peerClassLoadingThreadPoolSize=1
# despite not using igfs we have to allow pool of 1 thread (default = #available_proc_count)
${moduleId}.core.igfsThreadPoolSize=1
# Ignite default is same as public thread pool size
${moduleId}.core.dataStreamerThreadPoolSize=\${${moduleId}.core.publicThreadPoolSize}
# Ignite default is same as public thread pool size
${moduleId}.core.utilityCacheThreadPoolSize=\${${moduleId}.core.publicThreadPoolSize}
# despite not using query we have to allow pool of 1 thread (default = public thread pool size)
${moduleId}.core.queryThreadPoolSize=1
# Ignite default is 4 - must be lower than system thread pool size
${moduleId}.core.rebalanceThreadPoolSize=4

# 8K page size, 20 - 40 MiB system storage, 1 - 16 GiB default storage
${moduleId}.core.storage.pageSize=16384
${moduleId}.core.storage.systemInitialSize=20971520
${moduleId}.core.storage.systemMaxSize=41943040
${moduleId}.core.storage.defaultStorageRegion.initialSize=1073741824
${moduleId}.core.storage.defaultStorageRegion.maxSize=17179869184
${moduleId}.core.storage.defaultStorageRegion.swapPath=\${java.io.tmpdir}/${moduleId}/defaultDataRegionSwap

# Custom serialisations - global flags
${moduleId}.core.binary.optimisation.enabled=true
${moduleId}.core.binary.optimisation.useRawSerial=\${${moduleId}.core.binary.optimisation.enabled}
${moduleId}.core.binary.optimisation.useIdsWhenReasonable=\${${moduleId}.core.binary.optimisation.enabled}
${moduleId}.core.binary.optimisation.useIdsWhenPossible=\${${moduleId}.core.binary.optimisation.enabled}
${moduleId}.core.binary.optimisation.rawSerial.useVariableLengthIntegers=\${${moduleId}.core.binary.optimisation.useRawSerial}
# flags provided only for strange / special Alfresco system constellations
${moduleId}.core.binary.optimisation.rawSerial.handleNegativeIds=false
${moduleId}.core.binary.optimisation.rawSerial.handle128PiBFileSizes=false
${moduleId}.core.binary.optimisation.rawSerial.handle2EiBFileSizes=false

# Custom serialisation - specific flags (some trivial/general optimisations should always be enabled regardless of global flag)
${moduleId}.core.binary.optimisation.txnCacheKey.enabled=true
${moduleId}.core.binary.optimisation.txnCacheKey.useRawSerial=\${${moduleId}.core.binary.optimisation.useRawSerial}
${moduleId}.core.binary.optimisation.txnCacheKey.useVariableLengthIntegers=\${${moduleId}.core.binary.optimisation.rawSerial.useVariableLengthIntegers}
${moduleId}.core.binary.optimisation.cacheKey.enabled=true
${moduleId}.core.binary.optimisation.cacheKey.useRawSerial=\${${moduleId}.core.binary.optimisation.useRawSerial}
${moduleId}.core.binary.optimisation.cacheKey.useVariableLengthIntegers=\${${moduleId}.core.binary.optimisation.rawSerial.useVariableLengthIntegers}
${moduleId}.core.binary.optimisation.cacheValueKey.enabled=true
${moduleId}.core.binary.optimisation.cacheValueKey.useRawSerial=\${${moduleId}.core.binary.optimisation.useRawSerial}
${moduleId}.core.binary.optimisation.cacheValueKey.useVariableLengthIntegers=\${${moduleId}.core.binary.optimisation.rawSerial.useVariableLengthIntegers}
${moduleId}.core.binary.optimisation.storeRef.enabled=true
${moduleId}.core.binary.optimisation.storeRef.useRawSerial=\${${moduleId}.core.binary.optimisation.useRawSerial}
${moduleId}.core.binary.optimisation.storeRef.useVariableLengthIntegers=\${${moduleId}.core.binary.optimisation.rawSerial.useVariableLengthIntegers}
${moduleId}.core.binary.optimisation.nodeRef.enabled=true
${moduleId}.core.binary.optimisation.nodeRef.useRawSerial=\${${moduleId}.core.binary.optimisation.useRawSerial}
${moduleId}.core.binary.optimisation.nodeRef.useVariableLengthIntegers=\${${moduleId}.core.binary.optimisation.rawSerial.useVariableLengthIntegers}
${moduleId}.core.binary.optimisation.qname.enabled=true
${moduleId}.core.binary.optimisation.qname.useRawSerial=\${${moduleId}.core.binary.optimisation.useRawSerial}
${moduleId}.core.binary.optimisation.qname.useVariableLengthIntegers=\${${moduleId}.core.binary.optimisation.rawSerial.useVariableLengthIntegers}
${moduleId}.core.binary.optimisation.moduleVersionNumber.enabled=true
${moduleId}.core.binary.optimisation.moduleVersionNumber.useRawSerial=\${${moduleId}.core.binary.optimisation.useRawSerial}
${moduleId}.core.binary.optimisation.moduleVersionNumber.useVariableLengthIntegers=\${${moduleId}.core.binary.optimisation.rawSerial.useVariableLengthIntegers}
${moduleId}.core.binary.optimisation.contentData.enabled=true
${moduleId}.core.binary.optimisation.contentData.useRawSerial=\${${moduleId}.core.binary.optimisation.useRawSerial}
${moduleId}.core.binary.optimisation.contentData.useIdsWhenReasonable=\${${moduleId}.core.binary.optimisation.useIdsWhenReasonable}
${moduleId}.core.binary.optimisation.contentData.useVariableLengthIntegers=\${${moduleId}.core.binary.optimisation.rawSerial.useVariableLengthIntegers}
${moduleId}.core.binary.optimisation.contentData.handleNegativeIds=\${${moduleId}.core.binary.optimisation.rawSerial.handleNegativeIds}
${moduleId}.core.binary.optimisation.contentData.handle128PiBFileSizes=\${${moduleId}.core.binary.optimisation.rawSerial.handle128PiBFileSizes}
${moduleId}.core.binary.optimisation.contentData.handle2EiBFileSizes=\${${moduleId}.core.binary.optimisation.rawSerial.handle2EiBFileSizes}
${moduleId}.core.binary.optimisation.mlText.enabled=true
${moduleId}.core.binary.optimisation.mlText.useRawSerial=\${${moduleId}.core.binary.optimisation.useRawSerial}
${moduleId}.core.binary.optimisation.mlText.useIdsWhenReasonable=\${${moduleId}.core.binary.optimisation.useIdsWhenReasonable}
${moduleId}.core.binary.optimisation.mlText.useVariableLengthIntegers=\${${moduleId}.core.binary.optimisation.rawSerial.useVariableLengthIntegers}
${moduleId}.core.binary.optimisation.mlText.handleNegativeIds=\${${moduleId}.core.binary.optimisation.rawSerial.handleNegativeIds}
${moduleId}.core.binary.optimisation.nodeAspects.enabled=\${${moduleId}.core.binary.optimisation.enabled}
${moduleId}.core.binary.optimisation.nodeAspects.useRawSerial=\${${moduleId}.core.binary.optimisation.useRawSerial}
${moduleId}.core.binary.optimisation.nodeAspects.useIdsWhenReasonable=\${${moduleId}.core.binary.optimisation.useIdsWhenReasonable}
${moduleId}.core.binary.optimisation.nodeAspects.useVariableLengthIntegers=\${${moduleId}.core.binary.optimisation.rawSerial.useVariableLengthIntegers}
${moduleId}.core.binary.optimisation.nodeAspects.handleNegativeIds=\${${moduleId}.core.binary.optimisation.rawSerial.handleNegativeIds}
${moduleId}.core.binary.optimisation.nodeProperties.enabled=\${${moduleId}.core.binary.optimisation.enabled}
${moduleId}.core.binary.optimisation.nodeProperties.useRawSerial=\${${moduleId}.core.binary.optimisation.useRawSerial}
${moduleId}.core.binary.optimisation.nodeProperties.useIdsWhenReasonable=\${${moduleId}.core.binary.optimisation.useIdsWhenReasonable}
${moduleId}.core.binary.optimisation.nodeProperties.useIdsWhenPossible=\${${moduleId}.core.binary.optimisation.useIdsWhenPossible}
${moduleId}.core.binary.optimisation.nodeProperties.useVariableLengthIntegers=\${${moduleId}.core.binary.optimisation.rawSerial.useVariableLengthIntegers}
${moduleId}.core.binary.optimisation.nodeProperties.handleNegativeIds=\${${moduleId}.core.binary.optimisation.rawSerial.handleNegativeIds}

${moduleId}.caches.enabled=\${${moduleId}.core.enabled}

${moduleId}.caches.instance.name=\${${moduleId}.core.name}
${moduleId}.caches.partitionsCount=32
${moduleId}.caches.remoteSupport.enabled=false
${moduleId}.caches.ignoreDefaultEvictionConfiguration=true
# Flag was introduced to deal with https://issues.apache.org/jira/browse/IGNITE-11352
# Since this has been dealt with, it only serves to globally disable statistics for potential performance impact
${moduleId}.caches.disableAllStatistics=false

${moduleId}.webSessionCache.enabled=false
${moduleId}.webSessionCache.instanceName=\${${moduleId}.core.name}
${moduleId}.webSessionCache.cacheName=servlet.webSessionCache
${moduleId}.webSessionCache.retriesOnFailure=2
${moduleId}.webSessionCache.retriesTimeout=5000
${moduleId}.webSessionCache.keepBinary=true

${moduleId}.webSessionCache.cacheMode=REPLICATED
${moduleId}.webSessionCache.maxSize=10000

# Custom serialisations emitter config
${moduleId}.core.binary.type.org.alfresco.repo.cache.TransactionalCache$CacheRegionKey.enabled=\${${moduleId}.core.binary.optimisation.txnCacheKey.enabled}
${moduleId}.core.binary.type.org.alfresco.repo.cache.TransactionalCache$CacheRegionKey.serializer=Configuration.${moduleId}.core.binary.serializer.alfresco.optimisedTxnCacheRegionKey
${moduleId}.core.binary.type.org.alfresco.repo.cache.lookup.CacheRegionKey.enabled=\${${moduleId}.core.binary.optimisation.cacheKey.enabled}
${moduleId}.core.binary.type.org.alfresco.repo.cache.lookup.CacheRegionKey.serializer=Configuration.${moduleId}.core.binary.serializer.alfresco.optimisedCacheRegionKey
${moduleId}.core.binary.type.org.alfresco.repo.cache.lookup.CacheRegionValueKey.enabled=\${${moduleId}.core.binary.optimisation.cacheValueKey.enabled}
${moduleId}.core.binary.type.org.alfresco.repo.cache.lookup.CacheRegionValueKey.serializer=Configuration.${moduleId}.core.binary.serializer.alfresco.optimisedCacheRegionValueKey
${moduleId}.core.binary.type.org.alfresco.service.cmr.repository.StoreRef.enabled=\${${moduleId}.core.binary.optimisation.storeRef.enabled}
${moduleId}.core.binary.type.org.alfresco.service.cmr.repository.StoreRef.serializer=Configuration.${moduleId}.core.binary.serializer.alfresco.optimisedStoreRef
${moduleId}.core.binary.type.org.alfresco.service.cmr.repository.NodeRef.enabled=\${${moduleId}.core.binary.optimisation.nodeRef.enabled}
${moduleId}.core.binary.type.org.alfresco.service.cmr.repository.NodeRef.serializer=Configuration.${moduleId}.core.binary.serializer.alfresco.optimisedNodeRef
${moduleId}.core.binary.type.org.alfresco.service.namespace.QName.enabled=\${${moduleId}.core.binary.optimisation.qname.enabled}
${moduleId}.core.binary.type.org.alfresco.service.namespace.QName.serializer=Configuration.${moduleId}.core.binary.serializer.alfresco.optimisedQName
${moduleId}.core.binary.type.org.alfresco.service.cmr.repository.MLText.enabled=\${${moduleId}.core.binary.optimisation.mlText.enabled}
${moduleId}.core.binary.type.org.alfresco.service.cmr.repository.MLText.serializer=Configuration.${moduleId}.core.binary.serializer.alfresco.optimisedMLText
${moduleId}.core.binary.type.org.alfresco.repo.domain.node.ContentDataWithId.enabled=\${${moduleId}.core.binary.optimisation.contentData.enabled}
${moduleId}.core.binary.type.org.alfresco.repo.domain.node.ContentDataWithId.serializer=Configuration.${moduleId}.core.binary.serializer.alfresco.optimisedContentData
${moduleId}.core.binary.type.org.alfresco.service.cmr.repository.ContentData.enabled=\${${moduleId}.core.binary.optimisation.contentData.enabled}
${moduleId}.core.binary.type.org.alfresco.service.cmr.repository.ContentData.serializer=Configuration.${moduleId}.core.binary.serializer.alfresco.optimisedContentData
${moduleId}.core.binary.type.org.alfresco.repo.module.ModuleVersionNumber.enabled=\${${moduleId}.core.binary.optimisation.moduleVersionNumber.enabled}
${moduleId}.core.binary.type.org.alfresco.repo.module.ModuleVersionNumber.serializer=Configuration.${moduleId}.core.binary.serializer.alfresco.optimisedModuleVersionNumber

${moduleId}.core.binary.type.${project.basePackage}.cache.NodeAspectsCacheSet.enabled=\${${moduleId}.core.binary.optimisation.nodeAspects.enabled}
${moduleId}.core.binary.type.${project.basePackage}.cache.NodeAspectsCacheSet.serializer=Configuration.${moduleId}.core.binary.serializer.alfresco.optimisedNodeAspects
${moduleId}.core.binary.type.${project.basePackage}.cache.NodePropertiesCacheMap.enabled=\${${moduleId}.core.binary.optimisation.nodeProperties.enabled}
${moduleId}.core.binary.type.${project.basePackage}.cache.NodePropertiesCacheMap.serializer=Configuration.${moduleId}.core.binary.serializer.alfresco.optimisedNodeProperties

${moduleId}.caches.node.aspectsCache._process=\${${moduleId}.core.binary.optimisation.nodeAspects.enabled}
${moduleId}.caches.node.aspectsCache._className=${project.basePackage}.cache.ValueTransformingTransactionalCache
${moduleId}.caches.node.aspectsCache.property.valueTransformer.ref=${moduleId}-nodeAspectsCacheValueTransformer

${moduleId}.caches.node.propertiesCache._process=\${${moduleId}.core.binary.optimisation.nodeProperties.enabled}
${moduleId}.caches.node.propertiesCache._className=${project.basePackage}.cache.ValueTransformingTransactionalCache
${moduleId}.caches.node.propertiesCache.property.valueTransformer.ref=${moduleId}-nodePropertiesCacheValueTransformer


# Cache emitter config
# this configures "our" cache and lock store factories
${moduleId}.caches.cacheFactory._className=${project.basePackage}.cache.CacheFactoryImpl
# for some reason no bean forces Log4j hierarchy to be initialised sooner - so we do
${moduleId}.caches.cacheFactory._dependsOn=log4JHierarchyInit
${moduleId}.caches.cacheFactory.property.properties.ref=global-properties
${moduleId}.caches.cacheFactory.property.instanceName=\${${moduleId}.caches.instance.name}
${moduleId}.caches.cacheFactory.property.partitionsCount=\${${moduleId}.caches.partitionsCount}
${moduleId}.caches.cacheFactory.property.enableRemoteSupport=\${${moduleId}.caches.remoteSupport.enabled}
${moduleId}.caches.cacheFactory.property.ignoreDefaultEvictionConfiguration=\${${moduleId}.caches.ignoreDefaultEvictionConfiguration}
${moduleId}.caches.cacheFactory.property.disableAllStatistics=\${${moduleId}.caches.disableAllStatistics}

${moduleId}.caches.lockStoreFactory._className=${project.basePackage}.lock.LockStoreFactoryImpl
${moduleId}.caches.lockStoreFactory.property.instanceName=\${${moduleId}.caches.instance.name}
${moduleId}.caches.lockStoreFactory.property.partitionsCount=\${${moduleId}.caches.partitionsCount}
${moduleId}.caches.lockStoreFactory.property.enableRemoteSupport=\${${moduleId}.caches.remoteSupport.enabled}
${moduleId}.caches.lockStoreFactory.property.disableAllStatistics=\${${moduleId}.caches.disableAllStatistics}

# Alfresco cache configs
# Custom cache configurations to work with special service initialisation caches
cache.immutableSingletonSharedCache.ignite.cache.type=invalidatingDefaultSimple
cache.globalConfigSharedCache.ignite.cache.type=invalidatingDefaultSimple
cache.routingContentStoreSharedCache.ignite.cache.type=localDefaultSimple
cache.cachingContentStoreCache.ignite.cache.type=localDefaultSimple


# needs by-reference semantics due to "locked" state (IMHO a design bug which prevents full distribution + perfect synchronicity)
# also can't disable forceInvalidateOnPut as cache interaction design for this cache is bad (TTL, update put without prior read put to be able to detect actual change)
# this cache will cause significant increase in pointless re-read SQL queries in a grid when requests for same node are routed to different grid node every time
# TODO May need an even more special cache implementation for this one to fix Alfresco's issues
cache.node.nodesSharedCache.ignite.cache.type=invalidatingDefaultSimple

# tickets need to be fully replicated to avoid system locking up during joins
# cache usage pattern with getKeys() (not so smart an approach) would call out to other servers on ticket / auth check on each request otherwise
cache.ticketsCache.ignite.cache.type=replicated

# may have a few hundred to low thousands of entries
# these values are critical for almost any operation so they should always be fully replicated
cache.immutableEntitySharedCache.ignite.cache.type=replicated
# setup on-heap cache layer to optimise access
cache.immutableEntitySharedCache.ignite.heap.maxItems=5000
cache.immutableEntitySharedCache.ignite.heap.eviction-policy=${cache.immutableEntitySharedCache.eviction-policy}
# avoid stupendous amount of overhead + ping-pong invalidation/reload if set to invalidating
cache.immutableEntitySharedCache.ignite.forceInvalidateOnPut=false
cache.immutableEntitySharedCache.ignite.allowValueSentinels=false

# Some optimisations of cache configurations (smaller footprint due to usage patterns not requiring full Ignite caches)
# Will usually only have less than a handful of entries - a bit more if multi-tenancy is used
cache.node.rootNodesSharedCache.ignite.cache.type=invalidatingDefaultSimple
cache.node.rootNodesSharedCache.ignite.forceInvalidateOnPut=false
cache.node.rootNodesSharedCache.ignite.allowValueSentinels=false
cache.node.allRootNodesSharedCache.ignite.cache.type=invalidatingDefaultSimple
cache.node.allRootNodesSharedCache.ignite.forceInvalidateOnPut=false
cache.node.allRootNodesSharedCache.ignite.allowValueSentinels=false

# partition all the significantly large / growing caches (if not already fully-distributed in default Alfresco config)
cache.node.aspectsSharedCache.ignite.cache.type=partitioned
cache.node.propertiesSharedCache.ignite.cache.type=partitioned
cache.propertyValueCache.ignite.cache.type=partitioned
cache.propertyUniqueContextSharedCache.ignite.cache.type=partitioned

# will usually only have as many entries as tenants (typically just one)
# also, forceInvalidation (Alfresco default behaviour) might cause ping-pong invalidation/reload
# lastly, messages / resource bundles may be server-specific due to inclusion of resources from the local classpath, so should not be shared with servers in grid
cache.messagesSharedCache.ignite.cache.type=invalidatingDefaultSimple
cache.messagesSharedCache.ignite.forceInvalidateOnPut=false
cache.loadedResourceBundlesSharedCache.ignite.cache.type=invalidatingDefaultSimple
cache.loadedResourceBundlesSharedCache.ignite.forceInvalidateOnPut=false
cache.resourceBundleBaseNamesSharedCache.ignite.cache.type=invalidatingDefaultSimple
cache.resourceBundleBaseNamesSharedCache.ignite.forceInvalidateOnPut=false

# will usually have maybe a dozen to a few dozen entries
cache.propertyClassCache.ignite.cache.type=invalidatingDefaultSimple
cache.propertyClassCache.ignite.forceInvalidateOnPut=false
cache.propertyClassCache.ignite.allowValueSentinels=false

# just lookup caches - not essential enough for partitioning / replication
cache.node.childByNameSharedCache.ignite.cache.type=localDefaultSimple
cache.authoritySharedCache.ignite.cache.type=invalidatingDefaultSimple
cache.authoritySharedCache.ignite.forceInvalidateOnPut=false
cache.authoritySharedCache.ignite.allowValueSentinels=false
cache.authorityToChildAuthoritySharedCache.ignite.cache.type=invalidatingDefaultSimple
cache.authorityToChildAuthoritySharedCache.ignite.forceInvalidateOnPut=false
cache.authorityToChildAuthoritySharedCache.ignite.allowValueSentinels=false
cache.zoneToAuthoritySharedCache.ignite.cache.type=invalidatingDefaultSimple
cache.zoneToAuthoritySharedCache.ignite.forceInvalidateOnPut=false
cache.zoneToAuthoritySharedCache.ignite.allowValueSentinels=false

# As far as is known this is obsolete since 5.x
cache.webServicesQuerySessionSharedCache.ignite.cache.type=localDefaultSimple
# New cache in 5.2
cache.openCMISRegistrySharedCache.ignite.cache.type=invalidatingDefaultSimple


# compatibility with OOTBee Support Tools
ootbee-support-tools.cache.${project.basePackage}.cache.SimpleIgniteBackedCache.clearable=true
ootbee-support-tools.cache.${project.basePackage}.cache.InvalidatingCacheFacade.clearable=true